{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fedfe9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9840be9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i seriously hate one subject to death but now ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im so full of life i feel appalled</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sit here to write i start to dig out my feel...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive been really angry with r and i feel like a...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel suspicious if there is no one outside l...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Emotion\n",
       "0  i seriously hate one subject to death but now ...    fear\n",
       "1                 im so full of life i feel appalled   anger\n",
       "2  i sit here to write i start to dig out my feel...    fear\n",
       "3  ive been really angry with r and i feel like a...     joy\n",
       "4  i feel suspicious if there is no one outside l...    fear"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Emotion_classify_Data.csv') #Read Data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1d20ee7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fear', 'anger', 'joy'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Emotion'].unique() #to knowing our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d9ff34c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Comment    0\n",
       "Emotion    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum() #for checking that we don't have any nulls in our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec1eb89",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "39913b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "import re\n",
    "def preprocessing(text):\n",
    "    text = re.sub(r'\\W', ' ', text)      # Remove non-word characters (!!! , ...)\n",
    "    text = re.sub(r'\\s+', ' ', text)     # Remove extra spaces or using .strip()\n",
    "    text = text.lower()                   # Convert to lowercase\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8f903e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' my name is georgino i love football '"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "preprocessing(\"   My name is Georgino   ......  i love football !!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ac881c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Comment'] = data['Comment'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f623a0",
   "metadata": {},
   "source": [
    "# Tokenization , stemming and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "63b9c37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Gorgino\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Gorgino\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Gorgino\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenization\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4d243b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# important stop words in english\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "51b761b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'play'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming\n",
    "#remove suffixes\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "#testing\n",
    "stemmer.stem('playing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "95595d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'study'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatization \n",
    "#Gramatical information\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#testing\n",
    "lemmatizer.lemmatize(\"studies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5e5c9900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    words = nltk.word_tokenize(text) #split every word or character\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a24376b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'name georgino , watch tv , happi . mani studi .'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "tokenize(\"my name is Georgino ,i am watching tv , i am happy . i have many studies .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c02adfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data before tokenize\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    i seriously hate one subject to death but now ...\n",
       "1                   im so full of life i feel appalled\n",
       "2    i sit here to write i start to dig out my feel...\n",
       "3    ive been really angry with r and i feel like a...\n",
       "4    i feel suspicious if there is no one outside l...\n",
       "Name: Comment, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Data before tokenize\\n\")\n",
    "data['Comment'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f0c282e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Comment'] = data['Comment'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5fb4d687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after tokenize\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      serious hate one subject death feel reluct drop\n",
       "1                              im full life feel appal\n",
       "2    sit write start dig feel think afraid accept p...\n",
       "3    ive realli angri r feel like idiot trust first...\n",
       "4    feel suspici one outsid like raptur happen someth\n",
       "Name: Comment, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Data after tokenize\\n\")\n",
    "data['Comment'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "27e7d034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: anger = value: 0\n",
      "Label: fear = value: 1\n",
      "Label: joy = value: 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "data['Emotion'] = le.fit_transform(data['Emotion'])\n",
    "print(\"Label: anger = value: 0\")\n",
    "print(\"Label: fear = value: 1\")\n",
    "print(\"Label: joy = value: 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "841b7900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>serious hate one subject death feel reluct drop</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im full life feel appal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sit write start dig feel think afraid accept p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive realli angri r feel like idiot trust first...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feel suspici one outsid like raptur happen someth</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Emotion\n",
       "0    serious hate one subject death feel reluct drop        1\n",
       "1                            im full life feel appal        0\n",
       "2  sit write start dig feel think afraid accept p...        1\n",
       "3  ive realli angri r feel like idiot trust first...        2\n",
       "4  feel suspici one outsid like raptur happen someth        1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e315453",
   "metadata": {},
   "source": [
    "# Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2d97c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Comment'], data['Emotion'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6d1f95",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "da68e30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score on train data is  0.9793640766477153\n",
      "precision score on train data is  0.9794326442988702\n",
      "accuracy score on test data is  0.9259259259259259\n",
      "precision score on test data is  0.9258979865506665\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,precision_score \n",
    "\n",
    "log_reg = make_pipeline(TfidfVectorizer(), LogisticRegression())\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_log_pred=log_reg.predict(X_test)  #predicting on test data\n",
    "yt_log_pred=log_reg.predict(X_train)    #predicting on train data\n",
    "log_reg_acc=accuracy_score(y_test,y_log_pred)   #accuracy on test data\n",
    "log_reg_prec=precision_score(y_test,y_log_pred,average='macro') #precision on test data\n",
    "\n",
    "tr_log_reg_acc=accuracy_score(y_train,yt_log_pred)  #accuracy on test data\n",
    "tr_log_reg_prec=precision_score(y_train,yt_log_pred,average='macro') #precision on test data\n",
    "\n",
    "#printing accuracy and precision\n",
    "print(\"accuracy score on train data is \",tr_log_reg_acc)\n",
    "print(\"precision score on train data is \",tr_log_reg_prec)\n",
    "print(\"accuracy score on test data is \",log_reg_acc)\n",
    "print(\"precision score on test data is \",log_reg_prec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69955969",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f51604b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score on train data is  0.976416087597389\n",
      "precision score on train data is  0.9765993495178797\n",
      "accuracy score on test data is  0.8998316498316499\n",
      "precision score on test data is  0.9003105989072626\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "naive_bayes = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "naive_bayes_pred=naive_bayes.predict(X_test)    #prediction on test data\n",
    "naive_bayes_tr_pred=naive_bayes.predict(X_train)    #prediction on train data\n",
    "naive_bayes_acc=accuracy_score(y_test,naive_bayes_pred) #accuracy on test data\n",
    "naive_bayes_prec=precision_score(y_test,naive_bayes_pred,average='macro')   #precision on test data\n",
    "naive_bayes_tr_acc=accuracy_score(y_train,naive_bayes_tr_pred)  #accuracy on train data\n",
    "naive_bayes_tr_prec=precision_score(y_train,naive_bayes_tr_pred,average='macro')    #precision on train data\n",
    "#printing accuracy and precision\n",
    "print(\"accuracy score on train data is \",naive_bayes_tr_acc)\n",
    "print(\"precision score on train data is \",naive_bayes_tr_prec)\n",
    "print(\"accuracy score on test data is \",naive_bayes_acc)\n",
    "print(\"precision score on test data is \",naive_bayes_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e14b668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final function that Predict the emotion \n",
    "def predict_emotion(text):\n",
    "    # Preprocess input text\n",
    "    text = preprocessing(text)\n",
    "    text = tokenize(text)\n",
    "\n",
    "    # Predict with Logistic Regression\n",
    "    log_reg_prediction = log_reg.predict([text])[0]\n",
    "\n",
    "    # Predict with Naive Bayes\n",
    "    naive_bayes_prediction = naive_bayes.predict([text])[0]\n",
    "\n",
    "    # Inverse transform to get the original emotion labels (anger , fear , joy)\n",
    "    log_reg_prediction_label = le.inverse_transform([log_reg_prediction])[0]\n",
    "    naive_bayes_prediction_label = le.inverse_transform([naive_bayes_prediction])[0]\n",
    "\n",
    "    return log_reg_prediction_label, naive_bayes_prediction_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "97d924e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my favorite player scored yesterday !!\n",
      "input 1 - Logistic Regression: anger, Naive Bayes: anger\n",
      "input 2 - Logistic Regression: joy, Naive Bayes: joy\n",
      "input 3 - Logistic Regression: fear, Naive Bayes: fear\n",
      "input 4 - Logistic Regression: joy, Naive Bayes: joy\n"
     ]
    }
   ],
   "source": [
    "input1 = \"I really hate the school and i have a lot of homeworks !!!\"\n",
    "input2 = \"I am so full of energy , i feel excited to start my day\"\n",
    "input3 = \"I watched a horror movie ; I start to dig out my feelings...\"\n",
    "user_input = input(\"\")\n",
    "\n",
    "inp1_log_reg, inp1_naive_bayes = predict_emotion(input1)\n",
    "inp2_log_reg, inp2_naive_bayes = predict_emotion(input2)\n",
    "inp3_log_reg, inp3_naive_bayes = predict_emotion(input3)\n",
    "inp4_log_reg, inp4_naive_bayes = predict_emotion(user_input)\n",
    "\n",
    "\n",
    "# Print Results\n",
    "print(f\"input 1 - Logistic Regression: {inp1_log_reg}, Naive Bayes: {inp1_naive_bayes}\")\n",
    "print(f\"input 2 - Logistic Regression: {inp2_log_reg}, Naive Bayes: {inp2_naive_bayes}\")\n",
    "print(f\"input 3 - Logistic Regression: {inp3_log_reg}, Naive Bayes: {inp3_naive_bayes}\")\n",
    "print(f\"input 4 - Logistic Regression: {inp4_log_reg}, Naive Bayes: {inp4_naive_bayes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5713e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
